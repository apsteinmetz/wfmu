{
    "contents" : "library(RCurl)\n# #test\n# \n# # This page claims to be in iso-8859-1:\n# url <- 'http://www.elections.ca/content.aspx?section=res&dir=cir/list&document=index&lang=e#list'\n# elections <- read_html(url)\n# x <- elections %>% html_nodes(\"table\") %>% .[[2]] %>% html_table() %>% .$TO\n# # But something looks wrong:\n# x\n# # It's acutally UTF-8!\n# guess_encoding(x)\n# # We can repair this vector:\n# repair_encoding(x)\n# # But it's better to start from scratch with correctly encoded file\n# elections <- read_html(url, encoding = \"UTF-8\")\n# elections %>% html_nodes(\"table\") %>% .[[2]] %>% html_table() %>% .$TO\n# \n# html(\"http://www.sec.gov/litigation/suspensions.shtml\") %>%\n#   html_nodes(\"p+ table a\") %>% html_attr(name=\"href\")\n# \n# \n# url <- \"http://espn.go.com/golf/player/_/id/11/stuart-appleby\"\n# url %>% \n#   html %>% \n#   html_nodes(xpath='//li[contains(.,\"Age\")]') %>% \n#   html_text() %>% \n#   str_extract(\"[A-Z][a-z]{2,} [0-9]{1,2}, [0-9]{4}\")\n# \n\nomegahatExists = url.exists(\"http://www.omegahat.org\")\n# Regular HTTP\nif(omegahatExists) {\n  txt = getURL(\"http://www.omegahat.org/RCurl/\")\n  # Then we could parse the result.\n  if(require(XML))\n    htmlTreeParse(txt, asText = TRUE)\n}\n# You may need to set proxy details, etc.,  in the call to getURL\ntheurl <- \"https://en.wikipedia.org/wiki/Brazil_national_football_team\"\nwebpage <- getURL(theurl)\n# Process escape characters\nwebpage <- readLines(tc <- textConnection(webpage)); close(tc)\n\n# Parse the html tree, ignoring errors on the page\npagetree <- htmlTreeParse(webpage, error=function(...){})\n\n# Navigate your way through the tree. It may be possible to do this more efficiently using getNodeSet\nbody <- pagetree$children$html$children$body \ndivbodyContent <- body$children$div$children[[1]]$children$div$children[[4]]\ntables <- divbodyContent$children[names(divbodyContent)==\"table\"]\n\n#In this case, the required table is the only one with class \"wikitable sortable\"  \ntableclasses <- sapply(tables, function(x) x$attributes[\"class\"])\nthetable  <- tables[which(tableclasses==\"wikitable sortable\")]$table\n\n#Get columns headers\nheaders <- thetable$children[[1]]$children\ncolumnnames <- unname(sapply(headers, function(x) x$children$text$value))\n\n# Get rows from table\ncontent <- c()\nfor(i in 2:length(thetable$children))\n{\n  tablerow <- thetable$children[[i]]$children\n  opponent <- tablerow[[1]]$children[[2]]$children$text$value\n  others <- unname(sapply(tablerow[-1], function(x) x$children$text$value)) \n  content <- rbind(content, c(opponent, others))\n}\n\n# Convert to data frame\ncolnames(content) <- columnnames\nas.data.frame(content)\n\n\n#-------------------------------------------------------\n# \n# \n# #xp<-\"//body//center[2]//table[1]//ul[2]\"\n# \n# #t4<-html_node(playListRaw,xpath=xp)\n# t4<-html_nodes(playListRaw,xpath=\"//table\")[4:10]\n# t5<-html_nodes(t4,xpath='//a[contains(.,\"Playlists\")]') %>% html_attr(name=\"href\") \n# html_table(t4[1])\n# #-------------------------------------------------------\n# \n# t <- html_nodes(playListRaw,\"table\")[8]\n# t2<-html_nodes(t,\"table\")\n# html_table(t2[[2]],fill=T,trim=T)\n# t3<-html_nodes(t2[[2]],\"tr\")\n# \n# playListRaw%>%\n#   html_nodes(xpath='//tr[contains(.,\"Presidential play in\")]')%>%\n#   html_text()%>%  \n#   str_extract(\"[A-Z][a-z]{2,} [0-9]{1,2}, [0-9]{4}\")\n# \n# playListRaw%>%\n#   html_nodes(xpath='//tr[contains(.,\"docdate\")]')%>%\n#   html_text()%>%  \n#   str_extract(\"[A-Z][a-z]{2,} [0-9]{1,2}, [0-9]{4}\")\n# \n# playListRaw%>%\n#   html_nodes(xpath='//tr[contains(.,\"Republican Candidates\")]')%>%\n#   html_text()%>%  \n#   str_extract(\"[A-Z][a-z]{2,} [0-9]{1,2}, [0-9]{4}\")\n# \n# html_nodes(t2,\"a\")[1:16] %>%html_attr(\"href\")\n# \n# xpathSApply(playListRaw,\"//td[@class='docdate']\")\n# xpathSApply(playListRaw,\"//td[@class='doctext']\")\n# xpathSApply(playListRaw,\"//span[@class='doctext']\")\n# \n# # fill missing columns, and match by col names\n# DT1 = data.table(A=1:3,B=letters[1:3])\n# DT2 = data.table(B=letters[4:5],C=factor(1:2))\n# l = list(DT1,DT2)\n# rbindlist(l, use.names=TRUE, fill=TRUE)\n# \n# \n# #now we're serious\n# #-------------------------------------\n# makeplayList <- function(trow)\n#   # parse dates and description plus transcript URL, if any\n#   c(text=trow%>%html_nodes(\"td\")%>%html_text, url=trow%>%html_nodes(\"a\")%>%html_attr(\"href\"))\n# # -----------------------------------\n# tocURL <-\"http://www.presidency.ucsb.edu/plays.php\"\n# playListRaw<- html(tocURL)\n# \n# #narrow down page to relevant table\n# t <- html_nodes(playListRaw,\"table\")[8]\n# t2<-html_nodes(t,\"tr\")\n# t3<-t2[4:length(t3)]\n# \n# # extract data elements\n# playList<-(lapply(t3,makeplayList))\n# \n# options(stringsAsFactors=F)\n# t4<-  do.call(\"rbind.fill\",lapply(lapply(playList,t),as.data.frame))\n# t5<-filter(t4,is.na(url)==FALSE)\n# \n# startDate <- strptime(\"June 01,2015\",format=\"%B %d, %Y\")\n# strptime(playList[[166]][1],format=\"%B %d, %Y\")\n# \n# #not working\n# rbindlist(playList,fill=TRUE)\n# playTable<-data.frame(date=NULL,description=NULL,url=NULL)\n# \n",
    "created" : 1455285774681.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1134565217",
    "id" : "6776918E",
    "lastKnownWriteTime" : 1455314561,
    "path" : "~/R/wfmu/testscrape.R",
    "project_path" : "testscrape.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}