---
title: "How similar (or not) are WFMU DJs?"
output: html_notebook
author: Arthur Steinmetz
---
 

```{r, message=FALSE, warning=FALSE}


library(devtools)
#install_github('sinhrks/ggfortify')
library(ggplot2)
library(stringr)
library(tm)
library(dplyr)
library(tidyverse)
library(lubridate)
library(broom)
library("ggplot2")
#library(ggfortify)
library(xts)
library("wordcloud")
library("RColorBrewer")
#library("SnowballC")
library(igraph)
library(cluster)
# library(reshape2)
library(vegan) #similarity measures
library(Matrix)
library(knitr)


load("playlists.rdata")
load('djkey.rdata')
DJKey$DJ<-as.character(DJKey$DJ)
```
Do some analysis. What do we have?

```{r}
year_count<-playlists %>% 
  ungroup() %>% 
  transmute(Year_count=year(AirDate)) %>% 
  distinct() %>% nrow()
dj_count<-playlists %>% group_by(DJ) %>% summarise(DJs=n()) %>% nrow #DJs
show_count<-playlists %>% group_by(DJ,AirDate) %>% summarise(Shows=n()) %>% nrow()
#Artists
artist_count<-playlists %>% ungroup() %>% select(ArtistToken) %>% distinct() %>% nrow()

#songs
song_count<-playlists %>% ungroup() %>% select(ArtistToken,Title) %>% distinct() %>% nrow()

spins_count<-nrow(playlists) # spins

the_numbers<-data_frame(
           Count=c(year_count,dj_count,show_count,artist_count,song_count,spins_count),Stat=c("Years","DJs","Shows","Artists","Songs","Spins"))

the_numbers %>% 
  kable(caption="WFMU Archives by the Numbers",
        col.names=c('WFMU',' Archives by the Numbers'),
        format.args = list(big.mark=","))
```

```{r}

#playlists_raw by year
playlists %>% 
  ungroup() %>% 
  mutate(Year=trunc(decimal_date(AirDate)))  %>% 
  group_by(Year) %>% 
  summarise(SongCount=n()) %>% 
  arrange(Year) %>% 
  filter(Year > 1979) %>% 
  ggplot(aes(x=Year,y=SongCount))+geom_col()+labs(title="Songs Streamed or Aired on WFMU in a Year",x="Airdate")



```
```{r}

#playlists_raw by year
playlists %>% 
  ungroup() %>% 
  mutate(Year=trunc(decimal_date(AirDate)))  %>% 
  select(DJ,AirDate,Year) %>% 
  distinct() %>% 
  group_by(Year) %>% 
  summarise(ShowCount=n()) %>% 
  arrange(Year) %>% 
  filter(Year > 1979) %>% 
  ggplot(aes(x=Year,y=ShowCount))+geom_col()+labs(title="Shows Archived at WFMU.ORG by Airdate",x="Airdate")



```
#Popular WFMU artists
Who are the most popular artists?  One way to think about it is how widely played an artist is, regardless of how often they are played.  Has every DJ played them at least once?
```{r}
top_artists<-playlists %>%
  ungroup() %>% 
  select(DJ,ArtistToken) %>% 
  distinct() %>%
  group_by(ArtistToken) %>% 
  summarise(play_count=n()) %>% 
  arrange(desc(play_count))

kable(top_artists[1:10,])
```
96 out of 150 DJ's have played David Bowie at least once.  Can is a venerable industrial Krautrock act that is the second most widely played artist.  Wild!

Let's make a word cloud to visualize this.  I love word clouds!  
```{r}
#-------------------------------------------------------------------------------------
# We love wordclouds!
#scalefactor magnifies differences for wordcloud
#use filters to select on or off schedule and constrain show airdate range
scaleFactor=8
maxWords = 200
wordcloud(words = top_artists$ArtistToken, 
          freq = top_artists$play_count^scaleFactor,
          max.words=maxWords, 
          random.order=FALSE,rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"),
          scale = c(3,.3))

```
The above analysis ignores how often an artist is played.  Now let's take that into account. What artists get the most spins?

```{r, message=FALSE, warning=FALSE}

#-------------------------------------------------------------------------------------
# We love wordclouds!
#scalefactor magnifies differences for wordcloud
#use filters to select on or off schedule and constrain show airdate range
scaleFactor=2
maxWords = 200
  #most popular artists
  top_artists<-DJKey %>% 
    #filter(onSched==TRUE) %>% #on Sched or off?
    left_join(playlists)%>%
    group_by(ArtistToken)%>%
    #filter(AirDate<Sys.Date()-(365*5)) %>%  #date range?
    summarize(play_count=n())%>%
    arrange(desc(play_count))
wordcloud(words = top_artists$ArtistToken, 
          freq = top_artists$play_count^scaleFactor,
          max.words=maxWords, 
          random.order=FALSE,rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"),
          scale = c(3,.3))

```
Beach Boys!  I never would have guessed.  They are along way from Can!

We've gone back into ancient history but let's look at the recent past. Let's confine ourselves to the last five years using only DJ's who are on the current schedule. Who are the most popular artists among the current on-air DJs?
```{r, message=FALSE, warning=FALSE}

#-------------------------------------------------------------------------------------
# We love wordclouds!
#scalefactor magnifies differences for wordcloud
#use filters to select on or off schedule and constrain show airdate range
scaleFactor=1.3
maxWords = 200
  #most popular artists
  top_artists<-DJKey %>% 
    filter(onSched==TRUE) %>% #on Sched or off?
    left_join(playlists)%>%
    group_by(ArtistToken)%>%
    filter(AirDate<Sys.Date()-(365*5)) %>%  #date range?
    summarize(play_count=n())%>%
    arrange(desc(play_count))
wordcloud(words = top_artists$ArtistToken, 
          freq = top_artists$play_count^scaleFactor,
          max.words=maxWords, 
          random.order=FALSE,rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"),
          scale = c(3,.3))

```
What's with NRBQ?  How many DJ's play them in any given quarter?  Not many, it seems.
```{r}
artist_token='Nrbq'
cutoff_date=as.Date("2007-01-01")

dj_count<-playlists %>% 
  ungroup() %>% 
  filter(ArtistToken==artist_token) %>% 
  filter(AirDate > cutoff_date) %>% 
  mutate(AirDate=as.yearqtr(AirDate))  %>% 
  group_by(DJ,AirDate) %>% 
  summarise(Spins=n()) %>% 
  arrange(AirDate) %>% 
  group_by(AirDate) %>% 
  summarise(DJCount=n())

gg<-dj_count %>% ggplot(aes(x=AirDate,y=DJCount))+geom_col()
gg<-gg+labs(title=paste("How many DJs Spin",artist_token,"every Quarter?"))
gg<-gg+scale_x_continuous()
gg
```
So maybe certain DJs account for most of the plays?
```{r, message=FALSE, warning=FALSE}
play_count_by_DJ<-playlists %>% 
  ungroup() %>% 
  filter(AirDate > cutoff_date) %>% 
  mutate(DJ=as.character(DJ)) %>% 
  filter(ArtistToken==artist_token) %>% 
  mutate(AirDate=as.yearqtr(AirDate))  %>% 
  group_by(DJ,AirDate) %>% 
  summarise(Spins=n()) %>% 
  arrange(AirDate)

threshold <-5
pc1<- play_count_by_DJ %>% 
  filter(Spins>=threshold)

#lump together all DJ's who played the artist less than 'threshold' times
pc2<- play_count_by_DJ %>% 
  filter(Spins<threshold) %>% 
  group_by(AirDate) %>% 
  summarise(Spins=n()) %>% 
  mutate(ShowName='AllOther')

play_count_by_DJ<-pc1 %>% 
  left_join(DJKey) %>% 
  bind_rows(pc2) %>% 
  select(AirDate,ShowName,Spins)

gg<-play_count_by_DJ %>% ggplot(aes(x=AirDate,y=Spins,fill=ShowName))+geom_col()
gg<-gg+labs(title=paste("Who accounts for the most",artist_token,"plays every quarter?"))
gg<-gg+scale_x_continuous()
gg
```
Bob Brainen is the NRBQ show. Contrast that to The Beach Boys, where interest is more spread around.
```{r, message=FALSE, warning=FALSE}
artist_token<-'BeachBoys'

play_count_by_DJ<-playlists %>% 
  ungroup() %>% 
  filter(AirDate > cutoff_date) %>% 
  mutate(DJ=as.character(DJ)) %>% 
  filter(ArtistToken==artist_token) %>% 
  mutate(AirDate=as.yearqtr(AirDate))  %>% 
  group_by(DJ,AirDate) %>% 
  summarise(Spins=n()) %>% 
  arrange(AirDate)

threshold <-5
pc1<- play_count_by_DJ %>% 
  filter(Spins>=threshold)

#lump together all DJ's who played the artist less than 'threshold' times
pc2<- play_count_by_DJ %>% 
  filter(Spins<threshold) %>% 
  group_by(AirDate) %>% 
  summarise(Spins=n()) %>% 
  mutate(ShowName='AllOther')

play_count_by_DJ<-pc1 %>% 
  left_join(DJKey) %>% 
  bind_rows(pc2) %>% 
  select(AirDate,ShowName,Spins)

gg<-play_count_by_DJ %>% ggplot(aes(x=AirDate,y=Spins,fill=ShowName))+geom_col()
gg<-gg+labs(title=paste("Who accounts for the most",artist_token,"plays every quarter?"))
gg<-gg+scale_x_continuous()
gg
```
#Most played songs.
Everybody likes top 10 lists.  Here are WFMU's biggest hits by year! Looks like the Vivian Girls were the breakout band of 2008 with two songs in the top ten. Nice.

Warning:  A single DJ can greatly skew the results.  I tried to strip out songs with high play counts where only one DJ was responsible. Not a perfect process.  Once that was done, it only took about 10 plays to make the list.  WFMU is a very diverse station!  I once asked the music director of WDUB, my college station, why The Buggles were on the hot new artist list when I was the only one who played them....Oh.

```{r, message=FALSE, warning=FALSE}

#combined artist and title
playlists_songs<-playlists %>% 
  ungroup() %>% 
  transmute(DJ=as.character(DJ),AirDate=year(AirDate),Song=paste(ArtistToken,Title))

count_by_song<-playlists_songs %>%
  group_by(Song,AirDate) %>% 
  summarise(Song_Count=n()) %>% 
  arrange(desc(Song_Count))

top_10_long<-count_by_song %>%
  group_by(AirDate) %>%
  filter(AirDate>2001) %>% 
  arrange(AirDate,desc(Song_Count))

top_10<-NULL
years_top_10 <-unique(top_10_long$AirDate)
for (n in years_top_10){
  ten<-filter(top_10_long,AirDate==n) %>%
    pull(Song) %>% .[1:10] %>% as_tibble()
  top_10<-bind_cols(top_10,ten)
}
names(top_10)<-years_top_10
kable(top_10)
```
I dont' show years prior to 2002 because the number of DJ's who have playlists for airdates before 2002 is very small.
```{r}
dj_count<-playlists %>% 
  ungroup() %>% 
  mutate(AirDate=year(AirDate))  %>% 
  group_by(AirDate,DJ) %>% 
  summarise(Spins=n()) %>% 
  summarise(DJs=n()) %>% 
  filter(AirDate<2002)
  

gg<-dj_count %>% ggplot(aes(x=AirDate,y=DJs))+geom_col()
gg<-gg+labs(title=paste("How many DJs have Playlists earlier than 2002?"))
gg<-gg+scale_x_continuous()
gg

```

Diane "Kamikaze" Ferris is the only DJ with playlists from the 80s.  Yay, Diane! What a time capsule!  What were her most played artists back then?  More wordcloud!
```{r}
scaleFactor=2
maxWords = 200

DK<-playlists %>% 
  filter(AirDate<as.Date("1990-01-01")) %>% 
  group_by(ArtistToken) %>% 
  summarise(Spins=n()) %>% 
  arrange(desc(Spins))
  

wordcloud(words = DK$ArtistToken, 
          freq = DK$Spins^scaleFactor,
          max.words=maxWords, 
          random.order=FALSE,rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"),scale = c(3,.3))


```
Boy, that takes me back! 

#Dead Artist Effect. 

If there's a rock and roll heaven you can find out who's there by analyzing WFMU playlists.  Apparently, Amy Winehouse isn't in it.
```{r}
dead_artists=c('Bowie','Prince','AmyWinehouse','SharonJones','ChuckBerry','AllmanBrothers')

dead_artist_plays<-playlists %>% 
  ungroup() %>% 
  filter(AirDate > cutoff_date) %>% 
  filter(ArtistToken %in% dead_artists) %>% 
  mutate(AirDate=as.yearqtr(AirDate))  %>% 
  group_by(ArtistToken,AirDate) %>% 
  summarise(Spins=n()) %>% 
  arrange(AirDate)
gg<-dead_artist_plays %>% ggplot(aes(x=AirDate,y=Spins))
gg<-gg+geom_col()+facet_wrap(~ArtistToken)
gg<-gg+scale_x_continuous()+ggtitle("Dead Artist Effect")
gg
```
Prince is the prince but Bowie is the king.  The deaths of Prince and Davie Bowie led to some continuing interest in the artist, while plays for Chuck Berry, Sharon Jones and the Allman brothers dropped back to their pre-death background levels.  Amy Winehouse barely registers, before or after. To make this more visible, I'll clip the y-axis at 100. Now how does it look?
```{r}
#clip outliers
dead_artist_plays[dead_artist_plays$Spins>100,]$Spins=100

gg<-dead_artist_plays %>% ggplot(aes(x=AirDate,y=Spins))
gg<-gg+geom_col()+facet_wrap(~ArtistToken)
gg<-gg+scale_x_continuous()+ggtitle("Dead Artist Effect")
gg


```

#Durability of popular artists

How much stability to the most popular artists have in the rotation?

```{r, message=FALSE, warning=FALSE}

big_artists=top_artists$ArtistToken[1:6]

artist_trends<-playlists %>% 
  ungroup() %>% 
  filter(AirDate > cutoff_date) %>% 
  filter(ArtistToken %in% big_artists) %>% 
  mutate(AirDate=as.yearqtr(AirDate))  %>% 
  group_by(ArtistToken,AirDate) %>% 
  summarise(Spins=n()) %>% 
  arrange(AirDate)

#clip outliers
artist_trends[artist_trends$Spins>100,]$Spins=100

gg<-artist_trends %>% ggplot(aes(x=AirDate,y=Spins))+geom_col()
gg<-gg+facet_wrap(~ArtistToken)
gg<-gg+scale_x_continuous()+ylim(0,100)
gg<-gg+labs(title="Durability of popular artists\nQuarterly Plays",caption="Outliers clipped to 100")
gg

```

Who are the top trending (increasing rate of play) artists at WFMU over the last three years?

```{r}
cutoff_date<-Sys.Date()-(365*3)
cutoff_artists<-500

top_artists<-playlists %>% 
  ungroup() %>% 
  filter(AirDate>cutoff_date) %>%  #date range?
  group_by(ArtistToken)%>%
    summarize(play_count=n())%>%
    arrange(desc(play_count)) %>%
  .[1:cutoff_artists,] %>% 
  pull(ArtistToken)

#getting into the tidyverse over my head here.
#building linear trend models on entire data frame
#copying from https://blog.rstudio.com/2016/02/02/tidyr-0-4-0/ without
#fully understanding
trending_artists<-playlists %>% 
  ungroup() %>% 
  filter(AirDate > cutoff_date) %>% 
  filter(ArtistToken %in% top_artists) %>% 
  mutate(AirDate=as.yearqtr(AirDate))  %>% 
  group_by(ArtistToken,AirDate) %>% 
  summarise(Spins=n()) %>% 
  arrange(AirDate) %>% 
  group_by(ArtistToken) %>% 
  nest() %>% 
  #heavy stuff here
  mutate(model = purrr::map(data, ~ lm(Spins ~ AirDate, data = .))) %>% 
  unnest(model %>% purrr::map(broom::tidy)) %>% 
  filter(term=="AirDate") %>% 
  filter(statistic>2.0) %>% #only statistically significant trends
  arrange(desc(estimate)) %>% 
  .[1:12,] %>% #get top 12 strongest trends
  na.omit() %>% 
  pull(ArtistToken) #after all that, just a list of artists

# now we have the artists where there
# is a statistically significant trend in plays, ranked by trend strength.

artist_trends<-playlists %>% 
  ungroup() %>% 
  filter(AirDate > cutoff_date) %>% 
  filter(ArtistToken %in% trending_artists) %>% 
  mutate(AirDate=as.yearqtr(AirDate))  %>% 
  group_by(ArtistToken,AirDate) %>% 
  summarise(Spins=n()) %>% 
  arrange(AirDate)


gg<-artist_trends %>% ggplot(aes(x=AirDate,y=Spins))+geom_col()
gg<-gg+facet_wrap(~ArtistToken)
gg<-gg+scale_x_continuous()+ylim(0,100)
gg<-gg+labs(title="Trending Artists\nQuarterly Plays")
gg

```
No newer artists?  Lots of new stuff gets played on WFMU but nothing percolates into the conciousness of many DJs at once, it seems.  So "trending" seems to be irrelevant.  Despite that, let's see if we can identify similar DJs.

#Analyze similarity 

I use some "big data" techniques here.  I join all the artists a DJ has played into a single "document" and create a "document term matrix."  Then I compute an index of similarity for each possible pair of DJs using the "Bray" algorithm.  Finally I use "K-means" to create clusters of similar DJs.  I chose five clusters in two dimensions but this is arbitrary. Two dimensions is sufficient to explain nearly 40% of the artist variation among DJs.  

```{r}
#-------------------------------------------------------------  
#combineAllArtists
  concat_artists<- data_frame()
  #make sure there aren't extra levels
  playlists$DJ<-factor(playlists$DJ,as.character(unique(playlists$DJ)))
  for (dj in levels(playlists$DJ)){
    #put all words in string for each DJ
    concat_artists<-bind_rows(concat_artists,data_frame(DJ=dj,
                        Artists= playlists%>%
                          filter(DJ==dj)%>%
                          pull(ArtistToken)%>% 
                          paste(collapse=" ")%>%
                          str_replace_all("[^a-z ]","")%>%as.character() ,
                          onSched=DJKey%>%filter(DJ==dj)%>%pull(onSched)
                        ))
  }
  #artists should not have factor levels
  #concat_artists$Artists<-as.character(concat_artists$Artists)
  concat_artists<-filter(concat_artists,Artists!="") %>% distinct()


```
Create term document matrices
```{r}
print("Create document corpus and term document matrices")
djCorpus <- VCorpus(VectorSource(concat_artists$Artists))


for (i in 1:length(djCorpus)) {
  meta(djCorpus[[i]], tag="id") <- concat_artists$DJ[i]  
  meta(djCorpus[[i]], tag="DJ") <- concat_artists$DJ[i]
  meta(djCorpus[[i]], tag="onSched") <- (DJKey %>% 
    filter(DJ==concat_artists[1,1] %>% 
             pull()) %>% 
    pull(onSched))
}



#sched_status=c("on","off","all")
#status<-sched_status[1]
#idx <- switch(mic,
#              on = (meta(djCorpus, "onMic") == TRUE),
#              off = (meta(djCorpus, "onMic") == FALSE),
#              both = rep(TRUE,length(djCorpus))
#              )


#djtdm<-TermDocumentMatrix(djCorpus[idx])%>%removeSparseTerms(SPARSE)

#OR if you have the memory to pre-create
#make 3 Term Document Matrices where artist is in the column based on onmic status
#get roughly top 400 artists when removeSparseTerms(0.80) used. top 8000 when 0.95 sparse is used
SPARSE<- 0.95 #sparsity of term document matrices

# djtdm_all<-TermDocumentMatrix(djCorpus) #%>%removeSparseTerms(SPARSE)
# djtdm_on<-TermDocumentMatrix(djCorpus[meta(djCorpus, "onSched") == TRUE])%>%removeSparseTerms(SPARSE)
# djtdm_off<-TermDocumentMatrix(djCorpus[meta(djCorpus, "onSched") == FALSE])%>%removeSparseTerms(SPARSE)

# now create Document Term Matrix where DJs are the column
djdtm<-DocumentTermMatrix(djCorpus) %>%removeSparseTerms(SPARSE)
```

#Analyze similarity
```{r, warning=FALSE}
jaccard <- function(m) {
  #http://stackoverflow.com/questions/36220585/efficient-jaccard-similarity-documenttermmatrix
  ## common values:
  A <- tcrossprod(m)
  im <- which(A > 0, arr.ind=TRUE, useNames = FALSE)
  b <- rowSums(m)
  Aim <- A[im]
  J<-sparseMatrix(
    i = im[,1],
    j = im[,2],
    x = Aim / (b[im[,1]] + b[im[,2]] - Aim),
    dims = dim(A)
  )
  
  #preserve row/column names, if any
  rownames(J)<-rownames(m)
  colnames(J)<-rownames(m)
  return( J )
}  
#-----------------------------------------------------------
getSimilarity<-function(djdtm=djdtm){
  m2<-as.matrix(sign(djdtm))
  # get similarity
  j<-vegdist(m2,method="bray") %>% as.matrix()
  j<-1-j
  #j<-jaccard(m2)
  
  save(j,file="djSimilarity.RData")
  return(j)
}
#-----------------------------------------------------------


# get similarity index matrix using Jaccard
j<-getSimilarity(djdtm)

#cluster plot of DJs
set.seed(1)
CLUSTERS=5
  kdj<-kmeans(j,CLUSTERS)
  clust<-kdj$cluster
  #djCluster<-cbind(DJ=names(clust),data.frame(cluster=clust))
  
  #if ("cluster" %in% names(DJKey)){
  #  # then remove the cluster column
  #  DJKey<-select(DJKey,-cluster)
  #}
  # now replace with new clustering
  #DJKey<-inner_join(DJKey,djCluster)%>%arrange(cluster)
    
  
  clusplot(as.matrix(j), clust, main="DJ Similiarity Clusters",color=T, shade=T, labels=2, lines=0) 

```

```{r}
#----------------------------------------------------------
similarDJs<-function(whichDJ="TW",compareDJ="TM"){
  #djs for example
  #whichDJ <- "TW"
  #compareDJ<-"TM"
likeDJs<-data_frame(DJ=row.names(j),similarity=as.matrix(j)[,whichDJ]) %>% 
  arrange(desc(similarity)) #sort descending and remove self DJ

  #since we sorted in order of descending similarity the first row has the most similar DJ
  compareDJ<-likeDJs[1:3,1] %>% pull() 
  whichShow<-DJKey%>%filter(DJ==whichDJ)%>%.$ShowName%>%as.character()
  compareShow<-DJKey%>%filter(DJ %in% compareDJ)%>%.$ShowName%>%as.character()
  print(paste(whichShow,"is most similar to",compareShow))
  print(paste("Similarity Index:",format(pull(likeDJs[1:3,2]),digits=2),"/1.00"))
  
  commonArtists<-intersect(artistTokens[which(artistTokens$DJ==whichDJ),]$artistToken,artistTokens[which(artistTokens$DJ==compareDJ),]$artistToken)
  print(data.frame(Common_Artists=sample(commonArtists,20)))
}

similarDJs()
```

```{r}
likeDJs<-djdtm %>%
  as.matrix() %>% 
  vegdist(method="bray") %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  mutate(DJ1=rownames(.)) %>% 
  as_tibble() %>% 
  gather(DJ2,Similarity,-DJ1) %>% 
  mutate(Similarity=1-Similarity) %>% 
  filter(DJ1 != DJ2) %>%  #remove diagonals
  group_by(DJ1) %>% 
  arrange(desc(Similarity))

dj1 <- "DK"
dj2 <- "TM"

likeDJs %>% 
  ungroup() %>% 
  filter(DJ1==dj1) %>% 
  .[1:10,] %>% 
  rename(DJ=DJ2) %>% 
  left_join(DJKey) %>% 
  select(ShowName,Similarity)



songs1 <-playlists %>% 
  filter(DJ==dj1) %>% 
  group_by(ArtistToken) %>% 
  summarise(plays=n()) %>% 
  arrange(desc(plays))
songs2 <-playlists %>% 
  filter(DJ==dj2) %>% 
  group_by(ArtistToken) %>% 
  summarise(plays=n())%>% 
  arrange(desc(plays))

inner_join(songs2,songs1,by='ArtistToken') %>% 
  mutate(FaveIndex=plays.x+plays.y-abs(plays.x-plays.y)) %>% 
  arrange(desc(FaveIndex))
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
